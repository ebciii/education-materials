{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ip6kH_LkjiS"
   },
   "source": [
    "# Part One: Introduction & Classification with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZP67XlnkjiU"
   },
   "source": [
    "## Main Goals\n",
    "\n",
    "- Define Jupyter Notebooks\n",
    "- Learn what machine learning is\n",
    "- Represent data in `scikit-learn`\n",
    "- Classify data with the `iris` data\n",
    "- Modify and extend a classification pipeline to new models and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Notebooks in Google Colab\n",
    "\n",
    "This lesson is composed as a Jupyter Notebook. A Jupyter Notebook provides a computational environment in which to run, write, and edit code snippets alongside text and other content in Markdown format.\n",
    "\n",
    "You have a number of options for how to run Jupyter Notebooks. For this workshop, we will use the cloud-based computational environment *Google Colaboratory* (or *Google Colab*). To execute code in a cell, select it,  then either press the play button to the left of the code or use the keyboard shortcut `Command/Ctrl+Enter`. To edit code, just click the cell and start editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lTI3-7QkjiW"
   },
   "source": [
    "## About Scikit-Learn\n",
    "\n",
    "[`Scikit-Learn`](http://github.com/scikit-learn/scikit-learn) is a Python package designed to give access to **well-known** machine learning algorithms within Python code through a **clean, well-thought-out API**. Hundreds of contributors from around the world built it and it is used across industry and academia.\n",
    "\n",
    "`Scikit-Learn` is built upon Python's [`NumPy` (Numerical Python)](http://numpy.org) and [`SciPy` (Scientific Python)](http://scipy.org) libraries, which enable efficient in-core numerical and scientific computation within Python. Other popular ML libraries in Python include [`TensorFlow`](https://www.tensorflow.org/) and [`PyTorch`](https://pytorch.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Preparing data for classification\n",
    "2. Training a classifier on the Iris dataset\n",
    "3. Validating a model with test/train splits\n",
    "4. Applying the pipeline to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itYkBcy4kjiZ"
   },
   "source": [
    "### What is Machine Learning?\n",
    "\n",
    "In this section we will begin to explore the basic principles of machine learning.\n",
    "Machine Learning is a familiy of techniques that derive patterns from observed data and apply those patterns to previously unobserved data. \n",
    "\n",
    "One common flow in working with machine learning is to:\n",
    "\n",
    "1. Gather and observe a collection of data that is representative of the world\n",
    "2. Abstract out patterns, rules, and associations between a collection of observations (or \"features\") and a desired \"target\" variable, and \n",
    "3. Predict the target variable in previously unseen collection of data, given those features.\n",
    "\n",
    "To get started, we'll focus on one subset of machine learning approaches: **classification**. Classification is a supervised machine learning technique that attempts to predict a target category or label for a new observation, given other variables or **features** that describe that data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7J296gykjix"
   },
   "source": [
    "### How to represent data for machine learning classification\n",
    "\n",
    "Machine learning is about creating models from data; therefore we'll start by\n",
    "discussing how to represent data in a way the computer understands.  Along\n",
    "with this, we'll create `matplotlib` examples to visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqKTTohMkjiy"
   },
   "source": [
    "Classification algorithms implemented in `scikit-learn` expect the following data structures:\n",
    "\n",
    "**Feature matrix X:** A 2D array or matrix of features about our data (a collection of variables corresponding to each sample (each simple has a unique role).\n",
    "\n",
    "**Target vector y:** A 1D array or vector with a target variable, one per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVd-6y5fkji0"
   },
   "source": [
    "![Data Layout](https://github.com/jakevdp/sklearn_tutorial/blob/master/notebooks/images/data-layout.png?raw=1)\n",
    "\n",
    "(Figure from the [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a classifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZxVz_6mkji1"
   },
   "source": [
    "We're going to use the `iris` data bundled with `scikit-learn` (Anderson, 1936; Fisher, 1936). The data consists of measurements of the three different species of iris shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://raw.githubusercontent.com/jakevdp/sklearn_tutorial/master/notebooks/images/iris_setosa.jpg \"Iris Setosa\")\n",
    "\n",
    "Iris Setosa\n",
    "\n",
    "![alt text](http://raw.githubusercontent.com/jakevdp/sklearn_tutorial/master/notebooks/images/iris_versicolor.jpg \"Iris Versicolor\")\n",
    "\n",
    "Iris Versicolor\n",
    "\n",
    "![alt text](http://raw.githubusercontent.com/jakevdp/sklearn_tutorial/master/notebooks/images/iris_virginica.jpg \"Iris Virginica\")\n",
    "\n",
    "Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to setup our notebook and bring in relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data into a new Python object, `iris`. scikit-learn conveniently allows us to bundle all relevant functionality for sample datasets into one object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aU0WDPdkji9"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# make sure our data loaded in correctly\n",
    "print(iris.DESCR[1:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vKZbtI_MkjjB",
    "outputId": "dac9c84d-0e00-444e-84bf-7c953ac90368"
   },
   "outputs": [],
   "source": [
    "print(\"Below is what the data attribute of the iris object looks like:\\n\")\n",
    "print(iris.data)\n",
    "\n",
    "print(\"\\nAnd here are corresponding labels for each variable:\\n\")\n",
    "print(iris.feature_names)\n",
    "\n",
    "print(\"\\nBelow is what the target attribute of the iris object looks like:\\n\")\n",
    "print(iris.target)\n",
    "\n",
    "print(\"\\nAnd here is what the target label names look like:\\n\")\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a prettier version\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSvEc2ibkjjS"
   },
   "source": [
    "This data is four dimensional, but we can visualize two of the dimensions\n",
    "at a time using a simple scatter-plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "_hnWDgLJkjjT",
    "outputId": "9de3e032-8929-48f5-c198-720ff2682de7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index],\n",
    "            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.clim(-0.5, 2.5)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z50D1jsJkjjV"
   },
   "source": [
    "### Quick Exercise:\n",
    "\n",
    "**Change** `x_index` **and** `y_index` **in the above script\n",
    "and find a combination of two parameters\n",
    "which maximally separates the three classes.**\n",
    "\n",
    "This exercise is a preview of **dimensionality reduction**, which we'll see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier with k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors (kNN) is a simple, useful strategy for learning an estimator function. Draw the boundaries of your feature vector (in our case, similar to the plot above, but in 4D!) and find the k-nearest training points. Give each point a vote. Which class wins? Assin that region our target class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/knn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering a new observation in the future, plot the point according to its features in the feature vector space. What class does the point fall into? This gives us our class prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to play with an interactive version of k-NN, take a look at [this excellent blog post](http://scott.fortmann-roe.com/docs/BiasVariance.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on our iris classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a features matrix and target array\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant collection of classifiers into our code\n",
    "from sklearn import neighbors\n",
    "\n",
    "# instatiate the model\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fit the model\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how'd this model perform? test for accuracy (more on this shortly)\n",
    "knn.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
    "# call the \"predict\" method:\n",
    "\n",
    "sample_data = [[3, 5, 4, 2],]\n",
    "\n",
    "result = knn.predict(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the predicted label\n",
    "\n",
    "print(iris.target_names[result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, predicting a label will not be sufficient. We may also wish to know the confidence the model places in that prediction - or in other words, associate a probability with the each possible target labels.\n",
    "\n",
    "Many models in scikit-learn allow for the `.predict_proba()` method. Like `.predict()`, `.predict_proba()` accepts a set of observatrions as input. In this case, `.predict_proba()` also returns an array of probabilities assigned to each label. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba([[3, 5, 4, 2],])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHALLENGE 1: Think of a sample_data observation that would challenge your expectations. Modify sample_data and rerun the above cells. What results do you see? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHALLENGE 2: Instantiate a new knn model with a different n_neighbors parameter. Generate a score, prediction, and probabilities. How does it compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# knn2 = ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to set even more parameters?\n",
    "# take a look: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: Scikit-learn's estimator interface\n",
    "\n",
    "The `Scikit-learn` developers have tried to maintain a uniform user interface across all methods. We'll see examples of these below. Given a `scikit-learn` *estimator*\n",
    "object named `model`, the following methods are available:\n",
    "\n",
    "- Available in **all estimators**\n",
    "  + `model.fit()` : fit training data. For supervised learning applications,\n",
    "    this accepts two arguments: the data `X` and the labels `y` (e.g. `model.fit(X, y)`).\n",
    "    For unsupervised learning applications, this accepts only a single argument,\n",
    "    the data `X` (e.g. `model.fit(X)`).\n",
    "- Available in **supervised estimators**\n",
    "  + `model.predict()` : given a trained model, predict the label of a new set of data.\n",
    "    This method accepts one argument, the new data `X_new` (e.g. `model.predict(X_new)`),\n",
    "    and returns the learned label for each object in the array.\n",
    "  + `model.predict_proba()` : For classification problems, some estimators also provide\n",
    "    this method, which returns the probability that a new observation has each categorical label.\n",
    "    In this case, the label with the highest probability is returned by `model.predict()`.\n",
    "  + `model.score()` : for classification or regression problems, most (all?) estimators implement\n",
    "    a score method.  Scores are between 0 and 1, with a larger score indicating a better fit.\n",
    "- Available in **unsupervised estimators**\n",
    "  + `model.predict()` : predict labels in clustering algorithms.\n",
    "  + `model.transform()` : given an unsupervised model, transform new data into the new basis.\n",
    "    This also accepts one argument `X_new`, and returns the new representation of the data based\n",
    "    on the unsupervised model.\n",
    "  + `model.fit_transform()` : some estimators implement this method,\n",
    "    which more efficiently performs a fit and a transform on the same input data.\n",
    "    \n",
    "- Available in **some estimators**\n",
    "  + `model.predict_proba()`: return probabilities of class predictions, ordered by class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "\n",
    "An important piece of machine learning is **model validation**: that is, determining how well your model will generalize from the training data to future unlabeled data.\n",
    "\n",
    "With the iris data, let's look at our score with a knn with k=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare our predictions from earlier to the actual class labels\n",
    "# feel free to substitute knn with your own trained model\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "# fit the model\n",
    "knn.fit(X, y)\n",
    "knn.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more useful way to look at the results is to view the **confusion matrix**, or the matrix showing the frequency of inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# generate predictions for y\n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class, all 50 training samples are correctly identified. But this **does not mean that our model is perfect!** In particular, such a model generalizes extremely poorly to new data. We can simulate this by splitting our data into a *training set* and a *testing set*. `scikit-learn` contains some convenient routines to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fit on TRAINING data\n",
    "knn.fit(Xtrain, ytrain)\n",
    "\n",
    "# predict based on TEST data\n",
    "ypred = knn.predict(Xtest)\n",
    "print(confusion_matrix(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 1: Try rerunning the cell with train_test_split a few times to get a sense of performance across different splits. Also try modifying n_neighbors when instantiating models. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option One: Run classification on the iris dataset using a Support Vector Classifier model AND a test/train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Import your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load our data again\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "## create feature matrix and target array based on the dataset\n",
    "# X, y = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Set train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain, Xtest, ytrain, ytest = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Instantiate your model as an object (and, optionally, set any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "## instantiate your model as an object\n",
    "## in this case, let's use the 'rbf' kernel\n",
    "svm = svm.SVC(kernel='rbf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Fit your model to TRAINING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm..???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Apply your model (make predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new_sample = [[??, ??, ??, ??],]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Validate on TEST data (and, for your reference, compare to performance on training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score on train\n",
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option Two: Try classification with a new dataset: blood donation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we are going to use a new datase from **openml** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Import your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "blood = fetch_openml('blood-transfusion-service-center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blood.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this data does not have a .target_names property, only feature_names\n",
    "\n",
    "# print out to learn more about the dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Set train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Instantiate your model as an object (and, optionally, set any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Fit your model to TRAINING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Apply your model (make predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Validate on TEST data (and, for your reference, compare to performance on training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you first and foremost to my fantastic reviewers: Victor Ruiz, Sheila Braun, and Remo Williams.\n",
    "    \n",
    "These notebooks are based primarily on two sources:\n",
    "\n",
    "1. [Jake Vanderplas' Scikit-learn tutorial](https://github.com/jakevdp/sklearn_tutorial/) \n",
    "View [license](https://github.com/jakevdp/sklearn_tutorial/blob/master/LICENSE)\n",
    "2. [Andreas Müller's Introduction to Machine learning with Python workshop](https://github.com/amueller/ml-workshop-1-of-4) \n",
    "View [license](https://github.com/amueller/ml-workshop-1-of-4/blob/master/LICENSE)\n",
    "\n",
    "This notebook is a project of [Arcus Education](https://education.arcus.chop.edu/). The primary author is [Zoë Wilkinson Saldaña](https://github.com/zoews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 02.1-Machine-Learning-Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
