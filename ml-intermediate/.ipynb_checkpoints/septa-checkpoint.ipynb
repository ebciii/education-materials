{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Septa delays!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you train a model that successfully predicts SEPTA Regional Rail delays?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and tidy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've prepared the data a bit for you. Run the code blocks below to prepare your tidy dataframe, and feel free to make additional changes as you see fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "septa_data = pd.read_csv('https://raw.githubusercontent.com/arcus/education-materials/master/ml-intermediate/datasets/septa/septa_otp.csv')\n",
    "backup = septa_data.copy()\n",
    "septa_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to refresh your dataframe for any reason, use this backup data instead of querying github again\n",
    "# just in the spirit of being a good open-source-citizen ^_^\n",
    "# septa_data = backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data['delayed'] = septa_data.status.str.contains(\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.delayed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new delay_length column by extracting integers from the status column\n",
    "\n",
    "septa_data['delay_length'] = septa_data.status.str.extract(r'(\\d+)').fillna(0)\n",
    "septa_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create weekday and time columns (which may be useful features..!), and drop the now-extraneous status and timeStamp columns\n",
    "\n",
    "septa_data['timeStamp'] = pd.to_datetime(septa_data['timeStamp'])\n",
    "septa_data['weekday'] = septa_data['timeStamp'].dt.day_name()\n",
    "septa_data['time'] = [time.time() for time in septa_data['timeStamp']]\n",
    "septa_data = septa_data.drop(columns=['status', 'timeStamp', 'date'])\n",
    "\n",
    "\n",
    "septa_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's encode weekday as dummy vars\n",
    "septa_data = pd.get_dummies(data=septa_data, columns=['weekday'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, but take a look at all of the station names! these should definitely be treated as categorical rather than string data, and thus would be good candidates for us to encode as dummy vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.origin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should encode stations as dummy variables, too\n",
    "septa_data = pd.get_dummies(data=septa_data, columns=['origin', 'next_station'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's get rid of train_id as a feature (to create a generalized model of prediction based on other route features. there are >1000 train IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data['north'] = septa_data.direction.str.contains(\"N\")\n",
    "septa_data = septa_data.drop(columns=['train_id', 'direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that we are not doing any specific encoding to time here. What do you think? How might you like to encode time, and why? Consider doing extra feature engineering here if you're adventurous...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select our target variable (and drop the other 'delay' variable from our features!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W must decide on something to predict! If we want to approach this question as a classification question (i.e. delayed or not delayed), we should predict the delayed variable as the target, and exclude the delay length as a feature. \n",
    "\n",
    "Conversely, if we wish to predict the delay time as a regression task, we'll want to exclude the delayed boolean variable.\n",
    "\n",
    "For now, I've written code to approach this as a **classification** task, but feel free to rewrite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septa_data = septa_data.drop(columns=['delay_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we will start to implement a training process with cross-validation. The steps we will hit include:\n",
    "\n",
    "* Set up cross-validation\n",
    "* Define preprocessing and classification pipeline\n",
    "* Fit a model\n",
    "* Compute metrics\n",
    "* Interpret results\n",
    "* Try a new model? New parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get you started, here is the setup for cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create 5 stratified folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "class_labels = septa_data.delayed.values\n",
    "data = septa_data.values\n",
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "\n",
    "#split data between variables and outcome\n",
    "X, y = septa_data[septa_data.columns[septa_data.columns != 'delayed']].copy(), septa_data.delayed.copy()\n",
    "for train_index, test_index in skf.split(data, class_labels):\n",
    "  train_sets += [(X.iloc[train_index].copy(), y.iloc[train_index].copy())]\n",
    "  test_sets += [(X.iloc[test_index].copy(), y.iloc[test_index].copy())]\n",
    "  print(train_index.shape, test_index.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does one fold look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep going! See if you can transpose some of the materials from Victor's notebook to this example, or experiment with your own steps here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing and classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at victor's code, but consider rewriting as you go\n",
    "\n",
    "# for instance, consider trying a model other than decision tree!\n",
    "# e.g. support vector machine: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at victor's code, but consider rewriting as you go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at victor's code, but consider rewriting as you go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at victor's code, but consider rewriting as you go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a new model? New parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
